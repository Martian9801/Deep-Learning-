{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/adnanshaikh982001/secondmodelplantdisease?scriptVersionId=154485101\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch\n!pip install torchsummary\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:06:03.790365Z","iopub.execute_input":"2023-12-11T07:06:03.790682Z","iopub.status.idle":"2023-12-11T07:06:31.063556Z","shell.execute_reply.started":"2023-12-11T07:06:03.790656Z","shell.execute_reply":"2023-12-11T07:06:31.06246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:07:46.197341Z","iopub.execute_input":"2023-12-11T07:07:46.197745Z","iopub.status.idle":"2023-12-11T07:07:57.657713Z","shell.execute_reply.started":"2023-12-11T07:07:46.197714Z","shell.execute_reply":"2023-12-11T07:07:57.656693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n!pip install numpy==1.22.0  # Use the version that fits the SciPy requirements\n!pip install --upgrade scipy\nimport scipy\n#import numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nfrom torchsummary import summary\nfrom efficientnet_pytorch import EfficientNet  # Import EfficientNet\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:14:23.40408Z","iopub.execute_input":"2023-12-11T07:14:23.404527Z","iopub.status.idle":"2023-12-11T07:14:46.987795Z","shell.execute_reply.started":"2023-12-11T07:14:23.40449Z","shell.execute_reply":"2023-12-11T07:14:46.986642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\ntrain_dir = data_dir + \"/train\"\nvalid_dir = data_dir + \"/valid\"\ndiseases = os.listdir(train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:07.206112Z","iopub.execute_input":"2023-12-11T07:15:07.207559Z","iopub.status.idle":"2023-12-11T07:15:07.213961Z","shell.execute_reply.started":"2023-12-11T07:15:07.207515Z","shell.execute_reply":"2023-12-11T07:15:07.213178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(diseases)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:08.01472Z","iopub.execute_input":"2023-12-11T07:15:08.015088Z","iopub.status.idle":"2023-12-11T07:15:08.020169Z","shell.execute_reply.started":"2023-12-11T07:15:08.015059Z","shell.execute_reply":"2023-12-11T07:15:08.019117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total disease classes are :{}\".format(len(diseases)))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:08.920589Z","iopub.execute_input":"2023-12-11T07:15:08.921309Z","iopub.status.idle":"2023-12-11T07:15:08.925883Z","shell.execute_reply.started":"2023-12-11T07:15:08.921279Z","shell.execute_reply":"2023-12-11T07:15:08.925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plants = []\nNumberOfDiseases = 0 \nfor plant in diseases:\n    if plant.split(\"__\")[0] not in plants:\n        plants.append(plant.split(\"__\")[0])\n    if plant.split(\"__\")[1] != 'healthy':\n        NumberOfDiseases += 1","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:09.453571Z","iopub.execute_input":"2023-12-11T07:15:09.454326Z","iopub.status.idle":"2023-12-11T07:15:09.459533Z","shell.execute_reply.started":"2023-12-11T07:15:09.454294Z","shell.execute_reply":"2023-12-11T07:15:09.458556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Unique Plants are: \\n{plants}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:10.126661Z","iopub.execute_input":"2023-12-11T07:15:10.127031Z","iopub.status.idle":"2023-12-11T07:15:10.132032Z","shell.execute_reply.started":"2023-12-11T07:15:10.127002Z","shell.execute_reply":"2023-12-11T07:15:10.131039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of plants: {}\".format(len(plants)))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:10.866526Z","iopub.execute_input":"2023-12-11T07:15:10.866886Z","iopub.status.idle":"2023-12-11T07:15:10.87161Z","shell.execute_reply.started":"2023-12-11T07:15:10.866859Z","shell.execute_reply":"2023-12-11T07:15:10.870707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of diseases: {}\".format(NumberOfDiseases))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:11.616217Z","iopub.execute_input":"2023-12-11T07:15:11.616589Z","iopub.status.idle":"2023-12-11T07:15:11.622131Z","shell.execute_reply.started":"2023-12-11T07:15:11.616558Z","shell.execute_reply":"2023-12-11T07:15:11.621175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images for each disease\nnums = {}\nfor disease in diseases:\n    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\nimg_per_class","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:12.366917Z","iopub.execute_input":"2023-12-11T07:15:12.367312Z","iopub.status.idle":"2023-12-11T07:15:12.425839Z","shell.execute_reply.started":"2023-12-11T07:15:12.367273Z","shell.execute_reply":"2023-12-11T07:15:12.42484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = [n for n in range(38)]\nplt.figure(figsize=(20, 5))\nplt.bar(index, [n for n in nums.values()], width=0.3)\nplt.xlabel('Plants/Diseases', fontsize=10)\nplt.ylabel('No of images available', fontsize=10)\nplt.xticks(index, diseases, fontsize=5, rotation=90)\nplt.title('Images per each class of plant disease')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:13.082417Z","iopub.execute_input":"2023-12-11T07:15:13.08277Z","iopub.status.idle":"2023-12-11T07:15:13.812924Z","shell.execute_reply.started":"2023-12-11T07:15:13.082744Z","shell.execute_reply":"2023-12-11T07:15:13.812028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train = 0\nfor value in nums.values():\n    n_train += value\nprint(f\"There are {n_train} images for training\")","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:13.851096Z","iopub.execute_input":"2023-12-11T07:15:13.851372Z","iopub.status.idle":"2023-12-11T07:15:13.856502Z","shell.execute_reply.started":"2023-12-11T07:15:13.85135Z","shell.execute_reply":"2023-12-11T07:15:13.855652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = ImageFolder(train_dir, transform=transforms.ToTensor())\nvalid = ImageFolder(valid_dir, transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:15.105852Z","iopub.execute_input":"2023-12-11T07:15:15.10652Z","iopub.status.idle":"2023-12-11T07:15:29.6832Z","shell.execute_reply.started":"2023-12-11T07:15:15.106489Z","shell.execute_reply":"2023-12-11T07:15:29.682438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = train[0]\nprint(img.shape, label)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:29.684616Z","iopub.execute_input":"2023-12-11T07:15:29.684908Z","iopub.status.idle":"2023-12-11T07:15:29.691676Z","shell.execute_reply.started":"2023-12-11T07:15:29.684884Z","shell.execute_reply":"2023-12-11T07:15:29.690774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train.classes)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:45.390508Z","iopub.execute_input":"2023-12-11T07:15:45.391195Z","iopub.status.idle":"2023-12-11T07:15:45.396885Z","shell.execute_reply.started":"2023-12-11T07:15:45.391152Z","shell.execute_reply":"2023-12-11T07:15:45.395869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image(image,label):\n    print(\"label:\"+ train.classes[label]+\"(\"+str(label)+\")\")\n    plt.imshow(image.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:46.801252Z","iopub.execute_input":"2023-12-11T07:15:46.802081Z","iopub.status.idle":"2023-12-11T07:15:46.806634Z","shell.execute_reply.started":"2023-12-11T07:15:46.802047Z","shell.execute_reply":"2023-12-11T07:15:46.805643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:47.707137Z","iopub.execute_input":"2023-12-11T07:15:47.708002Z","iopub.status.idle":"2023-12-11T07:15:48.056275Z","shell.execute_reply.started":"2023-12-11T07:15:47.707968Z","shell.execute_reply":"2023-12-11T07:15:48.055439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[70000])","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:48.575754Z","iopub.execute_input":"2023-12-11T07:15:48.576495Z","iopub.status.idle":"2023-12-11T07:15:48.905231Z","shell.execute_reply.started":"2023-12-11T07:15:48.576458Z","shell.execute_reply":"2023-12-11T07:15:48.904318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the seed value\nrandom_seed = 7\ntorch.manual_seed(random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:49.588623Z","iopub.execute_input":"2023-12-11T07:15:49.589368Z","iopub.status.idle":"2023-12-11T07:15:49.595696Z","shell.execute_reply.started":"2023-12-11T07:15:49.589338Z","shell.execute_reply":"2023-12-11T07:15:49.594607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting the batch size\nbatch_size = 10","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:50.316099Z","iopub.execute_input":"2023-12-11T07:15:50.316961Z","iopub.status.idle":"2023-12-11T07:15:50.320899Z","shell.execute_reply.started":"2023-12-11T07:15:50.31693Z","shell.execute_reply":"2023-12-11T07:15:50.319875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoaders for training and validation\ntrain_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:51.096667Z","iopub.execute_input":"2023-12-11T07:15:51.097746Z","iopub.status.idle":"2023-12-11T07:15:51.120273Z","shell.execute_reply.started":"2023-12-11T07:15:51.097712Z","shell.execute_reply":"2023-12-11T07:15:51.119524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function to show a batch of training instances\ndef show_batch(data):\n    for images, labels in data:\n        fig, ax = plt.subplots(figsize=(30, 30))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n        break","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:52.929028Z","iopub.execute_input":"2023-12-11T07:15:52.9294Z","iopub.status.idle":"2023-12-11T07:15:52.93503Z","shell.execute_reply.started":"2023-12-11T07:15:52.929359Z","shell.execute_reply":"2023-12-11T07:15:52.934022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Images for first batch of training\nshow_batch(train_dl) ","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:54.276601Z","iopub.execute_input":"2023-12-11T07:15:54.276967Z","iopub.status.idle":"2023-12-11T07:15:55.562275Z","shell.execute_reply.started":"2023-12-11T07:15:54.276936Z","shell.execute_reply":"2023-12-11T07:15:55.56118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for moving data into GPU (if available)\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available:\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n\n# for moving data to device (CPU or GPU)\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# for loading in the device (GPU if available else CPU)\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n        \n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:56.341731Z","iopub.execute_input":"2023-12-11T07:15:56.342543Z","iopub.status.idle":"2023-12-11T07:15:56.350982Z","shell.execute_reply.started":"2023-12-11T07:15:56.34251Z","shell.execute_reply":"2023-12-11T07:15:56.349929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:57.165419Z","iopub.execute_input":"2023-12-11T07:15:57.166294Z","iopub.status.idle":"2023-12-11T07:15:57.172068Z","shell.execute_reply.started":"2023-12-11T07:15:57.166261Z","shell.execute_reply":"2023-12-11T07:15:57.171102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:58.10798Z","iopub.execute_input":"2023-12-11T07:15:58.108648Z","iopub.status.idle":"2023-12-11T07:15:58.113566Z","shell.execute_reply.started":"2023-12-11T07:15:58.108611Z","shell.execute_reply":"2023-12-11T07:15:58.112365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        return self.relu2(out) + x","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:15:59.949838Z","iopub.execute_input":"2023-12-11T07:15:59.950584Z","iopub.status.idle":"2023-12-11T07:15:59.957169Z","shell.execute_reply.started":"2023-12-11T07:15:59.95055Z","shell.execute_reply":"2023-12-11T07:15:59.956186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, recall_score\n\n# base class for the model\nclass ImageClassificationBase(nn.Module):\n    \n    def accuracy(self, outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        acc = torch.tensor(torch.sum(preds == labels).item() / len(preds))\n        return acc\n    \n    def recall(self, outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        recall = torch.tensor(recall_score(labels.cpu(), preds.cpu(), average='weighted', zero_division=1))\n        return recall\n    \n    def f1_score(self, outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        f1 = torch.tensor(f1_score(labels.cpu(), preds.cpu(), average='weighted'))\n        return f1\n    \n    def confusion_matrix(self, outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        cm = confusion_matrix(labels.cpu(), preds.cpu())\n        return cm\n    \n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                   # Generate prediction\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        acc = self.accuracy(out, labels)     # Calculate accuracy\n        recall = self.recall(out, labels)    # Calculate recall\n        f1 = self.f1_score(out, labels)      # Calculate F1 score\n        \n        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc, \"val_recall\": recall, \"val_f1\": f1}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x[\"val_loss\"] for x in outputs]\n        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n        batch_recall = [x[\"val_recall\"] for x in outputs]\n        batch_f1 = [x[\"val_f1\"] for x in outputs]\n\n        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n        epoch_accuracy = torch.stack(batch_accuracy).mean()\n        epoch_recall = torch.stack(batch_recall).mean()\n        epoch_f1 = torch.stack(batch_f1).mean()\n\n        return {\n            \"val_loss\": epoch_loss,\n            \"val_accuracy\": epoch_accuracy,\n            \"val_recall\": epoch_recall,\n            \"val_f1\": epoch_f1\n        }\n    \n    def epoch_end(self, epoch, result):\n        self.train_losses.append(result['train_loss'])\n        self.val_losses.append(result['val_loss'])\n        self.val_accuracies.append(result['val_accuracy'])\n        self.val_recalls.append(result['val_recall'])\n        self.val_f1_scores.append(result['val_f1'])\n\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, val_recall: {:.4f}, val_f1: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy'], result['val_recall'], result['val_f1']))\n\n    def plot_metrics(self):\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.plot([x['train_loss'] for x in history], label='Training Loss')\n        plt.plot([x['val_loss'] for x in history], label='Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n\n        # Plotting validation metrics\n        plt.subplot(1, 2, 2)\n        plt.plot([x['train_accuracy'] for x in history], label='Training Accuracy')\n        plt.plot([x['val_accuracy'] for x in history], label='Validation Accuracy')\n        plt.plot([x['train_recall'] for x in history], label='Training Recall')\n        plt.plot([x['val_recall'] for x in history], label='Validation Recall')\n        plt.plot([x['train_f1_score'] for x in history], label='Training F1 Score')\n        plt.plot([x['val_f1_score'] for x in history], label='Validation F1 Score')\n        plt.xlabel('Epoch')\n        plt.ylabel('Metrics')\n        plt.legend()\n\n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:32.033709Z","iopub.execute_input":"2023-12-11T07:35:32.03418Z","iopub.status.idle":"2023-12-11T07:35:32.061002Z","shell.execute_reply.started":"2023-12-11T07:35:32.034143Z","shell.execute_reply":"2023-12-11T07:35:32.060012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ConvBlock(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool:\n        layers.append(nn.MaxPool2d(4))\n    return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:32.855486Z","iopub.execute_input":"2023-12-11T07:35:32.856221Z","iopub.status.idle":"2023-12-11T07:35:32.861627Z","shell.execute_reply.started":"2023-12-11T07:35:32.856183Z","shell.execute_reply":"2023-12-11T07:35:32.86058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a new class for EfficientNet model\nclass EfficientNetModel(ImageClassificationBase):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)\n\n    def forward(self, xb):\n        return self.efficientnet(xb)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:33.756826Z","iopub.execute_input":"2023-12-11T07:35:33.757563Z","iopub.status.idle":"2023-12-11T07:35:33.762594Z","shell.execute_reply.started":"2023-12-11T07:35:33.757531Z","shell.execute_reply":"2023-12-11T07:35:33.761649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an instance of the EfficientNet model\nefficientnet_model = to_device(EfficientNetModel(len(train.classes)), device)\nefficientnet_model","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:34.494799Z","iopub.execute_input":"2023-12-11T07:35:34.495151Z","iopub.status.idle":"2023-12-11T07:35:34.613536Z","shell.execute_reply.started":"2023-12-11T07:35:34.495126Z","shell.execute_reply":"2023-12-11T07:35:34.612631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a summary of the EfficientNet model\nINPUT_SHAPE = (3, 256, 256)\nprint(summary(efficientnet_model.cuda(), (INPUT_SHAPE)))","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:35.208928Z","iopub.execute_input":"2023-12-11T07:35:35.209953Z","iopub.status.idle":"2023-12-11T07:35:35.263521Z","shell.execute_reply.started":"2023-12-11T07:35:35.209916Z","shell.execute_reply":"2023-12-11T07:35:35.262639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for training\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \n\ndef fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n                grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # scheduler for one cycle learning rate\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    \n    for epoch in range(epochs):\n        # Training\n        model.train()\n        train_losses = []\n        train_accuracies = []\n        train_recalls = []\n        train_f1_scores = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n            # Calculate and record training metrics\n            train_acc = model.accuracy(model(batch[0]), batch[1])\n            train_rec = model.recall(model(batch[0]), batch[1])\n            train_f1 = model.f1_score(model(batch[0]), batch[1])\n            \n            train_accuracies.append(train_acc)\n            train_recalls.append(train_rec)\n            train_f1_scores.append(train_f1)\n            \n        # Validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['train_accuracy'] = torch.stack(train_accuracies).mean().item()\n        result['train_recall'] = torch.stack(train_recalls).mean().item()\n        result['train_f1_score'] = torch.stack(train_f1_scores).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n    return history\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:35.836676Z","iopub.execute_input":"2023-12-11T07:35:35.837534Z","iopub.status.idle":"2023-12-11T07:35:35.850859Z","shell.execute_reply.started":"2023-12-11T07:35:35.837501Z","shell.execute_reply":"2023-12-11T07:35:35.849942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = [evaluate(efficientnet_model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:35:36.802404Z","iopub.execute_input":"2023-12-11T07:35:36.802778Z","iopub.status.idle":"2023-12-11T07:36:19.072596Z","shell.execute_reply.started":"2023-12-11T07:35:36.802747Z","shell.execute_reply":"2023-12-11T07:36:19.071549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2023-12-11T07:36:19.074916Z","iopub.execute_input":"2023-12-11T07:36:19.07581Z","iopub.status.idle":"2023-12-11T07:36:19.080424Z","shell.execute_reply.started":"2023-12-11T07:36:19.07577Z","shell.execute_reply":"2023-12-11T07:36:19.079436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the EfficientNet model\nhistory_efficientnet = [evaluate(efficientnet_model, valid_dl)]\nhistory_efficientnet += fit_OneCycle(epochs, max_lr, efficientnet_model, train_dl, valid_dl,\n                                     grad_clip=grad_clip, weight_decay=1e-4, opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T05:55:49.679757Z","iopub.execute_input":"2023-12-08T05:55:49.680737Z","iopub.status.idle":"2023-12-08T13:32:38.049859Z","shell.execute_reply.started":"2023-12-08T05:55:49.680682Z","shell.execute_reply":"2023-12-08T13:32:38.048953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_accuracy'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \ndef plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:40:23.124055Z","iopub.execute_input":"2023-12-08T14:40:23.124948Z","iopub.status.idle":"2023-12-08T14:40:23.136112Z","shell.execute_reply.started":"2023-12-08T14:40:23.124914Z","shell.execute_reply":"2023-12-08T14:40:23.135146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss', None) for x in history]\n    val_losses = [x['val_loss'] for x in history if 'val_loss' in x]\n\n    # Filter out None values\n    train_losses = [x for x in train_losses if x is not None]\n\n    # Move tensors to CPU\n    train_losses = torch.Tensor(train_losses).cpu().numpy()\n    val_losses = torch.Tensor(val_losses).cpu().numpy()\n\n    plt.plot(train_losses, '-bx', label='Training loss')\n    plt.plot(val_losses, '-rx', label='Validation loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Losses')\n    plt.show()\n\ndef plot_accuracies(history):\n    train_accs = [x.get('train_accuracy', None) for x in history]\n    val_accs = [x['val_accuracy'] for x in history if 'val_accuracy' in x]\n\n    # Filter out None values\n    train_accs = [x for x in train_accs if x is not None]\n\n    # Move tensors to CPU\n    train_accs = torch.Tensor(train_accs).cpu().numpy()\n    val_accs = torch.Tensor(val_accs).cpu().numpy()\n\n    plt.plot(train_accs, '-bx', label='Training accuracy')\n    plt.plot(val_accs, '-rx', label='Validation accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.title('Training and Validation Accuracies')\n    plt.show()\n\n# Call the modified functions\nplot_losses(history_efficientnet)\nplot_accuracies(history_efficientnet)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:40:25.583244Z","iopub.execute_input":"2023-12-08T14:40:25.58359Z","iopub.status.idle":"2023-12-08T14:40:25.627286Z","shell.execute_reply.started":"2023-12-08T14:40:25.583563Z","shell.execute_reply":"2023-12-08T14:40:25.626066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef get_metrics(model, data_loader):\n    model.eval()\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n\n            _, preds = torch.max(outputs, 1)\n\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='weighted')\n    recall = recall_score(all_labels, all_preds, average='weighted')\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n\n    return accuracy, precision, recall, f1\n\n# Calculate metrics on the validation set\naccuracy, precision, recall, f1 = get_metrics(model, valid_dl)\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\n\n# Plot the metrics\ndef plot_metrics(accuracy, precision, recall, f1):\n    metrics = [accuracy, precision, recall, f1]\n    labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n\n    plt.figure(figsize=(10, 6))\n\n    for metric, label in zip(metrics, labels):\n        plt.plot(metric, '-o', label=label)\n\n    plt.xlabel('Metric')\n    plt.ylabel('Value')\n    plt.title('Metrics over Validation Set')\n    plt.legend()\n    plt.show()\n\n# Call the function to plot metrics\nplot_metrics(accuracy, precision, recall, f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T14:38:37.330287Z","iopub.execute_input":"2023-12-08T14:38:37.330646Z","iopub.status.idle":"2023-12-08T14:38:37.374365Z","shell.execute_reply.started":"2023-12-08T14:38:37.330614Z","shell.execute_reply":"2023-12-08T14:38:37.373171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}